<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Adventcalender | kagari</title>

<meta name="keywords" content="" />
<meta name="description" content="これは琉大アドベントカレンダー12日目の記事です。
singularityでjupyterLab環境を作る 研究でsingularityを使っていたので、それについて少し書きます。
2022年9月頃まで動かしていた環境なので、今は動かない可能性がありますが参考になれば幸いです。
why singularity？ 2022年の4月頃、研究でGPT-2を学習とデータの前処理をしようと思っていました。
ただ、その期間はちょうど研究室にあるGPUサーバを色んな人が使っていて空きがなかったため、学科サーバで学習させることに。
ちなみに、研究室のサーバがコア数14スレッド数28メモリ128GBなのに対して学科サーバがコア数22スレッド数88メモリ512GBなので、前処理用にちょっとくらい適当なコードを書いてもパワーで押し切れてしまう環境です。
学科サーバではどうやらsingularityという仮想技術？を用いているため、私もそれを使ってやることにしました。
singularity &#43; GPU singularityの使い方に関してはsyskan、nal先生がとても丁寧にまとめているので、リンクを貼って満足します。
 Singularityのすゝめ SingularityとSlurmの実践例 新システムとしてTesla V100SでSingularityでSlurmな環境が導入されたので、BERT with SentencePiece を日本語 Wikipedia で学習してモデルを公開しましたを使ってlivedoor ニュースコーパスのジャンル推定するfine-tuningしてみた。  singularity &#43; GPU &#43; jupyterLab 本題ですが、jupyterLabをsingularity &#43; GPU環境で動かします。
といってもやることはpipかcondaでinstallするだけで十分です。
下がそのdefinition fileです。
ほとんどDockerfileと同じように書けます。 umahara からのオススメを受けてmambaを使っています（速くて良い）。
# singularity/environment.def Bootstrap: docker From: pytorch/pytorch:1.11.0-cuda11.3-cudnn8-runtime %post conda config --add channels conda-forge conda config --remove channels defaults conda install mamba mamba install -y jupyterlab matplotlib ipywidgets scikit-learn これをbuildしてexecすれば立ち上がるはず…！
ここで、GPUを使用するためには--nvオプションを付ける必要があります。
# build $ singularity build -f -s singularity/image singularity/environment.">
<meta name="author" content="">
<link rel="canonical" href="//kagari.github.io/note/2022/adventcalender/" />
<link href="//kagari.github.io/assets/css/stylesheet.min.521ef667ad8ddd035b65438a1d85fd5707173fefe338d23bc2544d116fa47efb.css" integrity="sha256-Uh72Z62N3QNbZUOKHYX9VwcXP&#43;/jONI7wlRNEW&#43;kfvs=" rel="preload stylesheet"
    as="style">

<link rel="icon" href="//kagari.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="//kagari.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="//kagari.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="//kagari.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="//kagari.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.91.2" />


<meta property="og:title" content="Adventcalender" />
<meta property="og:description" content="これは琉大アドベントカレンダー12日目の記事です。
singularityでjupyterLab環境を作る 研究でsingularityを使っていたので、それについて少し書きます。
2022年9月頃まで動かしていた環境なので、今は動かない可能性がありますが参考になれば幸いです。
why singularity？ 2022年の4月頃、研究でGPT-2を学習とデータの前処理をしようと思っていました。
ただ、その期間はちょうど研究室にあるGPUサーバを色んな人が使っていて空きがなかったため、学科サーバで学習させることに。
ちなみに、研究室のサーバがコア数14スレッド数28メモリ128GBなのに対して学科サーバがコア数22スレッド数88メモリ512GBなので、前処理用にちょっとくらい適当なコードを書いてもパワーで押し切れてしまう環境です。
学科サーバではどうやらsingularityという仮想技術？を用いているため、私もそれを使ってやることにしました。
singularity &#43; GPU singularityの使い方に関してはsyskan、nal先生がとても丁寧にまとめているので、リンクを貼って満足します。
 Singularityのすゝめ SingularityとSlurmの実践例 新システムとしてTesla V100SでSingularityでSlurmな環境が導入されたので、BERT with SentencePiece を日本語 Wikipedia で学習してモデルを公開しましたを使ってlivedoor ニュースコーパスのジャンル推定するfine-tuningしてみた。  singularity &#43; GPU &#43; jupyterLab 本題ですが、jupyterLabをsingularity &#43; GPU環境で動かします。
といってもやることはpipかcondaでinstallするだけで十分です。
下がそのdefinition fileです。
ほとんどDockerfileと同じように書けます。 umahara からのオススメを受けてmambaを使っています（速くて良い）。
# singularity/environment.def Bootstrap: docker From: pytorch/pytorch:1.11.0-cuda11.3-cudnn8-runtime %post conda config --add channels conda-forge conda config --remove channels defaults conda install mamba mamba install -y jupyterlab matplotlib ipywidgets scikit-learn これをbuildしてexecすれば立ち上がるはず…！
ここで、GPUを使用するためには--nvオプションを付ける必要があります。
# build $ singularity build -f -s singularity/image singularity/environment." />
<meta property="og:type" content="article" />
<meta property="og:url" content="//kagari.github.io/note/2022/adventcalender/" />
<meta property="article:published_time" content="2022-12-12T18:12:12+09:00" />
<meta property="article:modified_time" content="2022-12-12T18:12:12+09:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Adventcalender"/>
<meta name="twitter:description" content="これは琉大アドベントカレンダー12日目の記事です。
singularityでjupyterLab環境を作る 研究でsingularityを使っていたので、それについて少し書きます。
2022年9月頃まで動かしていた環境なので、今は動かない可能性がありますが参考になれば幸いです。
why singularity？ 2022年の4月頃、研究でGPT-2を学習とデータの前処理をしようと思っていました。
ただ、その期間はちょうど研究室にあるGPUサーバを色んな人が使っていて空きがなかったため、学科サーバで学習させることに。
ちなみに、研究室のサーバがコア数14スレッド数28メモリ128GBなのに対して学科サーバがコア数22スレッド数88メモリ512GBなので、前処理用にちょっとくらい適当なコードを書いてもパワーで押し切れてしまう環境です。
学科サーバではどうやらsingularityという仮想技術？を用いているため、私もそれを使ってやることにしました。
singularity &#43; GPU singularityの使い方に関してはsyskan、nal先生がとても丁寧にまとめているので、リンクを貼って満足します。
 Singularityのすゝめ SingularityとSlurmの実践例 新システムとしてTesla V100SでSingularityでSlurmな環境が導入されたので、BERT with SentencePiece を日本語 Wikipedia で学習してモデルを公開しましたを使ってlivedoor ニュースコーパスのジャンル推定するfine-tuningしてみた。  singularity &#43; GPU &#43; jupyterLab 本題ですが、jupyterLabをsingularity &#43; GPU環境で動かします。
といってもやることはpipかcondaでinstallするだけで十分です。
下がそのdefinition fileです。
ほとんどDockerfileと同じように書けます。 umahara からのオススメを受けてmambaを使っています（速くて良い）。
# singularity/environment.def Bootstrap: docker From: pytorch/pytorch:1.11.0-cuda11.3-cudnn8-runtime %post conda config --add channels conda-forge conda config --remove channels defaults conda install mamba mamba install -y jupyterlab matplotlib ipywidgets scikit-learn これをbuildしてexecすれば立ち上がるはず…！
ここで、GPUを使用するためには--nvオプションを付ける必要があります。
# build $ singularity build -f -s singularity/image singularity/environment."/>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Adventcalender",
  "name": "Adventcalender",
  "description": "これは琉大アドベントカレンダー12日目の記事です。\nsingularityでjupyterLab環境を作る 研究でsingularityを使っていたので、それについて少し書きます。\n2022年9月頃まで動かしていた環境なので、今は動かない可能性がありますが参考になれば幸いです。\nwhy singularity？ 2022年の4月頃、研究でGPT-2を学習と …",
  "keywords": [
    
  ],
  "articleBody": "これは琉大アドベントカレンダー12日目の記事です。\nsingularityでjupyterLab環境を作る 研究でsingularityを使っていたので、それについて少し書きます。\n2022年9月頃まで動かしていた環境なので、今は動かない可能性がありますが参考になれば幸いです。\nwhy singularity？ 2022年の4月頃、研究でGPT-2を学習とデータの前処理をしようと思っていました。\nただ、その期間はちょうど研究室にあるGPUサーバを色んな人が使っていて空きがなかったため、学科サーバで学習させることに。\nちなみに、研究室のサーバがコア数14スレッド数28メモリ128GBなのに対して学科サーバがコア数22スレッド数88メモリ512GBなので、前処理用にちょっとくらい適当なコードを書いてもパワーで押し切れてしまう環境です。\n学科サーバではどうやらsingularityという仮想技術？を用いているため、私もそれを使ってやることにしました。\nsingularity + GPU singularityの使い方に関してはsyskan、nal先生がとても丁寧にまとめているので、リンクを貼って満足します。\n Singularityのすゝめ SingularityとSlurmの実践例 新システムとしてTesla V100SでSingularityでSlurmな環境が導入されたので、BERT with SentencePiece を日本語 Wikipedia で学習してモデルを公開しましたを使ってlivedoor ニュースコーパスのジャンル推定するfine-tuningしてみた。  singularity + GPU + jupyterLab 本題ですが、jupyterLabをsingularity + GPU環境で動かします。\nといってもやることはpipかcondaでinstallするだけで十分です。\n下がそのdefinition fileです。\nほとんどDockerfileと同じように書けます。 umahara からのオススメを受けてmambaを使っています（速くて良い）。\n# singularity/environment.def Bootstrap: docker From: pytorch/pytorch:1.11.0-cuda11.3-cudnn8-runtime %post conda config --add channels conda-forge conda config --remove channels defaults conda install mamba mamba install -y jupyterlab matplotlib ipywidgets scikit-learn これをbuildしてexecすれば立ち上がるはず…！\nここで、GPUを使用するためには--nvオプションを付ける必要があります。\n# build $ singularity build -f -s singularity/image singularity/environment.def # jupyter lab $ singularity exec --nv singularity/image jupyter-lab --allow-root --no-browser --port 8888 ちなみに、シェルに入りたい場合は以下のようにすれば良いはずです。\n$ singularity shell --nv singularity/image 毎回の起動を楽にするために execで毎回 jupyter-lab ... と書くのが大変なので、%runscriptセクションを使って実行したいコマンドを記述すると簡単に起動することができます。\n# singularity/environment.def Bootstrap: docker From: pytorch/pytorch:1.11.0-cuda11.3-cudnn8-runtime %post conda config --add channels conda-forge conda config --remove channels defaults conda install mamba mamba install -y jupyterlab matplotlib ipywidgets scikit-learn %runscript jupyter-lab --allow-root --no-browser --port 8888 もう一度buildして…\n実行の際にはこれを打つだけ！\n$ singularity run --nv singularity/image.sif 最後に 学科サーバの環境がものすごく良いので、もし「もっと多くのメモリが欲しい」「もっとコア数が欲しい」と思っているのであればぜひ使ってみてください！\n締めに学科サーバ上で88並列で処理した際の画像を貼っておきます。\n",
  "wordCount" : "143",
  "inLanguage": "en",
  "datePublished": "2022-12-12T18:12:12+09:00",
  "dateModified": "2022-12-12T18:12:12+09:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "//kagari.github.io/note/2022/adventcalender/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "kagari",
    "logo": {
      "@type": "ImageObject",
      "url": "//kagari.github.io/favicon.ico"
    }
  }
}
</script>



</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        .theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="//kagari.github.io" accesskey="h" title="kagari (Alt + H)">kagari</a>
            <span class="logo-switches">
                <span class="theme-toggle" title="(Alt + T)">
                    <a id="theme-toggle" accesskey="t">
                        <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                        </svg>
                        <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <circle cx="12" cy="12" r="5"></circle>
                            <line x1="12" y1="1" x2="12" y2="3"></line>
                            <line x1="12" y1="21" x2="12" y2="23"></line>
                            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                            <line x1="1" y1="12" x2="3" y2="12"></line>
                            <line x1="21" y1="12" x2="23" y2="12"></line>
                            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                        </svg>
                    </a>
                </span>
                
            </span>
        </div>
        <ul class="menu" id="menu" onscroll="menu_on_scroll()"></ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    <h1 class="post-title">
      Adventcalender
    </h1>
    <div class="post-meta">December 12, 2022

    </div>
  </header> 

  <div class="post-content">
<p>これは<a href="https://adventar.org/calendars/7496">琉大アドベントカレンダー</a>12日目の記事です。</p>
<h1 id="singularityでjupyterlab環境を作る">singularityでjupyterLab環境を作る<a hidden class="anchor" aria-hidden="true" href="#singularityでjupyterlab環境を作る">#</a></h1>
<p>研究でsingularityを使っていたので、それについて少し書きます。<br>
2022年9月頃まで動かしていた環境なので、今は動かない可能性がありますが参考になれば幸いです。</p>
<h2 id="why-singularity">why singularity？<a hidden class="anchor" aria-hidden="true" href="#why-singularity">#</a></h2>
<p>2022年の4月頃、研究でGPT-2を学習とデータの前処理をしようと思っていました。<br>
ただ、その期間はちょうど研究室にあるGPUサーバを色んな人が使っていて空きがなかったため、学科サーバで学習させることに。<br>
ちなみに、研究室のサーバがコア数14スレッド数28メモリ128GBなのに対して学科サーバがコア数22スレッド数88メモリ512GBなので、前処理用にちょっとくらい適当なコードを書いてもパワーで押し切れてしまう環境です。</p>
<p>学科サーバではどうやらsingularityという仮想技術？を用いているため、私もそれを使ってやることにしました。</p>
<h2 id="singularity--gpu">singularity + GPU<a hidden class="anchor" aria-hidden="true" href="#singularity--gpu">#</a></h2>
<p>singularityの使い方に関してはsyskan、nal先生がとても丁寧にまとめているので、リンクを貼って満足します。</p>
<ul>
<li><a href="https://ie.u-ryukyu.ac.jp/syskan/service/singularity/">Singularityのすゝめ</a></li>
<li><a href="https://ie.u-ryukyu.ac.jp/syskan/opening-introduction/singularity-slurm.html">SingularityとSlurmの実践例</a></li>
<li><a href="https://ie.u-ryukyu.ac.jp/tnal/afterhugo/20201219-2/">新システムとしてTesla V100SでSingularityでSlurmな環境が導入されたので、BERT with SentencePiece を日本語 Wikipedia で学習してモデルを公開しましたを使ってlivedoor ニュースコーパスのジャンル推定するfine-tuningしてみた。</a></li>
</ul>
<h2 id="singularity--gpu--jupyterlab">singularity + GPU + jupyterLab<a hidden class="anchor" aria-hidden="true" href="#singularity--gpu--jupyterlab">#</a></h2>
<p>本題ですが、jupyterLabをsingularity + GPU環境で動かします。<br>
といってもやることはpipかcondaでinstallするだけで十分です。</p>
<p>下がそのdefinition fileです。<br>
ほとんどDockerfileと同じように書けます。
umahara からのオススメを受けてmambaを使っています（速くて良い）。</p>
<pre tabindex="0"><code># singularity/environment.def
Bootstrap: docker
From: pytorch/pytorch:1.11.0-cuda11.3-cudnn8-runtime

%post
    conda config --add channels conda-forge
    conda config --remove channels defaults
    conda install mamba
    mamba install -y jupyterlab matplotlib ipywidgets scikit-learn
</code></pre><p>これをbuildしてexecすれば立ち上がるはず…！<br>
ここで、GPUを使用するためには<code>--nv</code>オプションを付ける必要があります。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console"># build
$ singularity build -f -s singularity/image singularity/environment.def
<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span># jupyter lab
$ singularity exec --nv singularity/image jupyter-lab --allow-root --no-browser --port <span style="color:#ae81ff">8888</span>
</code></pre></div><p>ちなみに、シェルに入りたい場合は以下のようにすれば良いはずです。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console">$ singularity shell --nv singularity/image
</code></pre></div><h2 id="毎回の起動を楽にするために">毎回の起動を楽にするために<a hidden class="anchor" aria-hidden="true" href="#毎回の起動を楽にするために">#</a></h2>
<p>execで毎回 <code>jupyter-lab ...</code> と書くのが大変なので、<code>%runscript</code>セクションを使って実行したいコマンドを記述すると簡単に起動することができます。</p>
<pre tabindex="0"><code># singularity/environment.def
Bootstrap: docker
From: pytorch/pytorch:1.11.0-cuda11.3-cudnn8-runtime

%post
    conda config --add channels conda-forge
    conda config --remove channels defaults
    conda install mamba
    mamba install -y jupyterlab matplotlib ipywidgets scikit-learn

%runscript
    jupyter-lab --allow-root --no-browser --port 8888
</code></pre><p>もう一度buildして…<br>
実行の際にはこれを打つだけ！</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-console" data-lang="console">$ singularity run --nv singularity/image.sif
</code></pre></div><h2 id="最後に">最後に<a hidden class="anchor" aria-hidden="true" href="#最後に">#</a></h2>
<p>学科サーバの環境がものすごく良いので、もし「もっと多くのメモリが欲しい」「もっとコア数が欲しい」と思っているのであればぜひ使ってみてください！</p>
<p>締めに学科サーバ上で88並列で処理した際の画像を貼っておきます。</p>
<p><img src="figs/88threads.png" alt="88threads"></p>

</div>
  <footer class="post-footer">
  </footer>
</article>
    </main><footer class="footer">
    <span>&copy; 2022 <a href="//kagari.github.io">kagari</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<a href="#top">
    <button class="top-link" id="top-link" type="button" aria-label="go to top" title="Go to Top (Alt + G)"
        accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>



<script defer src="//kagari.github.io/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                behavior: "smooth"
            });
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.replaceState(null, null, `#${id}`);
            }
        });
    });
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>

</body>

</html>
